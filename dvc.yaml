stages:

  download_dataset:
    cmd: >-
      kaggle datasets download
      -d ruchi798/bookcrossing-dataset
      -p data/raw/
    outs:
    - data/raw/bookcrossing-dataset.zip

  extract_dataset:
    cmd: >-
      unzip data/raw/bookcrossing-dataset.zip
      -d data/raw/
    deps:
    - data/raw/bookcrossing-dataset.zip
    outs:
    - data/raw/Book reviews/Book reviews/BX-Users.csv
    - data/raw/Book reviews/Book reviews/BX_Books.csv
    - data/raw/Book reviews/Book reviews/BX-Book-Ratings.csv
    - data/raw/Books Data with Category Language and Summary/Preprocessed_data.csv

  pack_dataset:
    cmd: >-
      poetry run python -m src.dataset
      "data/raw/Book reviews/Book reviews/BX-Users.csv"
      "data/raw/Book reviews/Book reviews/BX_Books.csv"
      "data/raw/Book reviews/Book reviews/BX-Book-Ratings.csv"
      data/interim/dataset.cloudpickle
      --limit=${dataset_limit}
    deps:
    - src/dataset.py
    - data/raw/Book reviews/Book reviews/BX-Users.csv
    - data/raw/Book reviews/Book reviews/BX_Books.csv
    - data/raw/Book reviews/Book reviews/BX-Book-Ratings.csv
    outs:
    - data/interim/dataset.cloudpickle

  build_features:
    cmd: >-
      poetry run python -m src.features
      data/interim/dataset.cloudpickle
      data/interim/features.cloudpickle
      --chunk_size=${embedding_chunk_size}
      --device=${compute_device}
    deps:
    - src/features.py
    - data/interim/dataset.cloudpickle
    outs:
    - data/interim/features.cloudpickle

  train:
    foreach: ${train_params}
    do:
      cmd: >-
        poetry run python -m src.modeling.train
        data/interim/features.cloudpickle
        models/model_${key}.pth
        --device=${compute_device}
        ${item}
      deps:
      - src/modeling/model.py
      - src/modeling/data_loader.py
      - src/modeling/train.py
      - data/interim/features.cloudpickle
      outs:
      - models/model_${key}.pth

  predict:
    foreach: ${train_params}
    do:
      cmd: >-
        poetry run python -m src.modeling.predict
        data/interim/features.cloudpickle
        models/model_${key}.pth
        data/processed/predicted_${key}.parquet
        --device ${compute_device}
        --hidden_dim ${item.hidden_dim}
        --output_dim ${item.output_dim}
        --dropout_p ${item.dropout_p}
      deps:
      - src/modeling/model.py
      - src/modeling/data_loader.py
      - src/modeling/predict.py
      - data/interim/features.cloudpickle
      - models/model_${key}.pth
      outs:
      - data/processed/predicted_${key}.parquet

  evaluate:
    foreach: ${train_params}
    do:
      cmd: >-
        poetry run python -m src.evaluate
        data/processed/predicted.parquet
        reports/figures/evaluate-${key}/
      deps:
      - src/evaluate.py
      - data/processed/predicted_${key}.parquet
      outs:
      - reports/figures/evaluate-${key}/
